{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "class PlotHelper():\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self._f = None\n",
    "        self._ax = None\n",
    "        self.kvals = defaultdict(list)\n",
    "\n",
    "    def add(self, **kval):\n",
    "        for k, v in kval.items():\n",
    "            self.kvals[k].append(v)\n",
    "\n",
    "    @property\n",
    "    def fig(self):\n",
    "        if self._f is None:\n",
    "            self.new()\n",
    "        return self._f\n",
    "\n",
    "    @property\n",
    "    def ax(self):\n",
    "        if self._ax is None:\n",
    "            self.new()\n",
    "        return self._ax\n",
    "\n",
    "    def new(self):\n",
    "        self._f, self._ax = plt.subplots(1,1)\n",
    "        plt.ion()\n",
    "        self.fig.show()\n",
    "\n",
    "    def show(self):\n",
    "        names = []\n",
    "        self.ax.clear()\n",
    "        for k, v in self.kvals.items():\n",
    "            names.append(k)\n",
    "            self.ax.plot(v)\n",
    "        self.ax.legend(names)\n",
    "        self.fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_balanced_subset(dataset, n_per_class):\n",
    "    classes = dataset.targets.unique()\n",
    "    indices = [(dataset.targets == c).nonzero(as_tuple=False) [:n_per_class] for c in classes]\n",
    "    indices = torch.stack(indices).flatten()\n",
    "    return torch.utils.data.Subset(dataset, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x.reshape(10,2)\n",
    "\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch, cons=None, plot_loss=None):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        output = output.reshape(10,10)\n",
    "        \n",
    "        loss = F.cross_entropy(output[:1], target)\n",
    "        closs = cons(output) if cons else torch.tensor(0).to(device)\n",
    "        \n",
    "        loss += closs\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Logging\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for data, target in test_loader:\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            output = output.reshape(10,10)\n",
    "            # sum up batch loss\n",
    "            test_loss += F.cross_entropy(output[:1], target, reduction='sum').item()\n",
    "            \n",
    "            # get the index of the max log-probability\n",
    "            pred = output[:1].argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from pytorch_constraints.constraint import constraint\n",
    "from pytorch_constraints.brute_force_solver import SatisfactionBruteForceSolver\n",
    "from pytorch_constraints.sampling_solver import SamplingSolver, WeightedSamplingSolver\n",
    "\n",
    "def only_one(x):\n",
    "    return sum(x) == 1\n",
    "\n",
    "class Args:\n",
    "    batch_size = 1\n",
    "    test_batch_size = 1000\n",
    "    epochs = 1\n",
    "    lr = 1.0\n",
    "    gamma = 0.7\n",
    "    seed = 1\n",
    "    log_interval = 10\n",
    "    use_cuda = False\n",
    "    n_per_class = 100\n",
    "    \n",
    "# Plotting\n",
    "plot_loss = PlotHelper()\n",
    "    \n",
    "args = Args()\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if args.use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'batch_size': args.batch_size}\n",
    "if args.use_cuda:\n",
    "    kwargs.update({'num_workers': 1,\n",
    "                   'pin_memory': True,\n",
    "                   'shuffle': True},\n",
    "                 )\n",
    "\n",
    "# Prepare dataset transformations\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "# Load train and test splits\n",
    "train_split = datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transform)\n",
    "test_split = datasets.MNIST('../data', train=False,\n",
    "                   transform=transform)\n",
    "\n",
    "# Sample a balanced subset of the train set\n",
    "train_split = sample_balanced_subset(train_split, args.n_per_class)\n",
    "\n",
    "# Create train, validation and test data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_split,**kwargs)\n",
    "test_loader  = torch.utils.data.DataLoader(test_split, **kwargs)\n",
    "\n",
    "# Constraint to be applied on unlabeled data\n",
    "only_one_constraint = constraint(only_one, SatisfactionBruteForceSolver())\n",
    "# only_one_constraint = constraint(only_one, WeightedSamplingSolver(num_samples=200))\n",
    "# only_one_constraint = constraint(only_one, SamplingSolver(num_samples=200))\n",
    "# Move model to correct device\n",
    "model = Net().to(device)\n",
    "\n",
    "# Set up optimizer\n",
    "# optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, y in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:09<00:00, 53.70it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# # Plotting\n",
    "plot_loss = PlotHelper()\n",
    "\n",
    "for i in tqdm(range(500)):\n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    output = model(X)\n",
    "    loss = F.cross_entropy(output[:,1].reshape(1,10), y)\n",
    "    closs = only_one_constraint(output)\n",
    "    total_loss = loss + closs\n",
    "    \n",
    "    plot_loss.add(loss=loss.data, closs=closs.data, )\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "plot_loss.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.softmax(model(X), dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
