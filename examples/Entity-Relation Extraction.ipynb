{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import Vocab\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "with open(\"conll04_test.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "tokens = []\n",
    "for datum in data:\n",
    "    tokens += datum['tokens']\n",
    "\n",
    "vocab = Vocab(Counter(tokens), vectors=\"glove.6B.100d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY_TO_ID = {\"O\":0,\"Loc\":1, \"Org\":2, \"Peop\":3, \"Other\":4}\n",
    "REL_TO_ID = {\"*\":0, \"Work_For_arg1\":1, \"Kill_arg1\":2, \"OrgBased_In_arg1\":3, \"Live_In_arg1\":4,\n",
    "             \"Located_In_arg1\":5, \"Work_For_arg2\":6, \"Kill_arg2\":7, \"OrgBased_In_arg2\":8,\n",
    "             \"Live_In_arg2\":9, \"Located_In_arg2\":10}\n",
    "\n",
    "class DataLoader(object):\n",
    "    def __init__(self, filename, vocab, batch_size=1):\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        with open(filename) as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        self.data = self.preprocess(data, vocab)\n",
    "        self.data = [self.data[i: i + batch_size] for i in range(0, len(self.data), batch_size)]\n",
    "        \n",
    "    def preprocess(self, data, vocab):\n",
    "        \n",
    "        processed = []\n",
    "        for i, d in enumerate(data):\n",
    "#             print(i)\n",
    "            if i == 10:\n",
    "                break\n",
    "            tokens = to_ids([t.lower() for t in d['tokens']], vocab.stoi)\n",
    "\n",
    "            entities = ['O'] * len(tokens)\n",
    "            for e in d['entities']:\n",
    "                entities[e['end']] = e['type']\n",
    "            entities = to_ids(entities, ENTITY_TO_ID)\n",
    "\n",
    "            relations = []\n",
    "            for r in d['relations']:\n",
    "                curr = ['*'] * len(tokens)\n",
    "                curr[r['head']] = r['type'] + \"_arg1\"\n",
    "                curr[r['tail']] = r['type'] + \"_arg2\"\n",
    "\n",
    "                relations += [to_ids(curr, REL_TO_ID)]\n",
    "                \n",
    "            relations = relations[0]\n",
    "\n",
    "            processed += [(tokens, entities, relations)]\n",
    "                \n",
    "        return processed\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        if not isinstance(key, int):\n",
    "            raise TypeError\n",
    "        \n",
    "        if key < 0 or key >= self.__len__():\n",
    "            raise IndexError\n",
    "            \n",
    "        return list(zip(*self.data[key]))\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for i in range(self.__len__()):\n",
    "            yield self.__getitem__(i)\n",
    "            \n",
    "def to_ids(tokens, vocab):\n",
    "    \"\"\" Maps a list of tokens to the corresponding ids given by the dictionary, vocab\"\"\"\n",
    "\n",
    "    ids = [vocab[t] if t in vocab else 0 for t in tokens]\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class NER_Net(torch.nn.Module):\n",
    "    '''Simple Named Entity Recognition model'''\n",
    "\n",
    "    def __init__(self, vocab_size, num_classes, hidden_dim=50, embedding_dim=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # layers\n",
    "        self.embedding = torch.nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.embedding.weight = torch.nn.Parameter(vocab.vectors)\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(self.embedding_dim, self.hidden_dim, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(self.hidden_dim, num_classes)\n",
    "\n",
    "        # Initialize fully connected layer\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight, gain=1)\n",
    "\n",
    "    def forward(self, s):\n",
    "        s = self.embedding(s)   # dim: batch_size x batch_max_len x embedding_dim\n",
    "        s, _ = self.lstm(s)     # dim: batch_size x batch_max_len x lstm_hidden_dim\n",
    "        s = self.fc(s)          # dim: batch_size*batch_max_len x num_tags\n",
    "\n",
    "        return s\n",
    "    \n",
    "    \n",
    "class RE_Net(torch.nn.Module):\n",
    "    '''Simple Relation extraction model'''\n",
    "\n",
    "    def __init__(self, vocab_size, num_classes, hidden_dim=50, embedding_dim=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # layers\n",
    "        self.embedding = torch.nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.embedding.weight = torch.nn.Parameter(vocab.vectors)\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(self.embedding_dim, self.hidden_dim, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(self.hidden_dim, num_classes)\n",
    "\n",
    "        # Initialize fully connected layer\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight, gain=1)\n",
    "\n",
    "    def forward(self, s):\n",
    "        s = self.embedding(s)   # dim: batch_size x batch_max_len x embedding_dim\n",
    "        s, _ = self.lstm(s)     # dim: batch_size x batch_max_len x lstm_hidden_dim\n",
    "        s = self.fc(s)          # dim: batch_size*batch_max_len x num_tags\n",
    "\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataLoader(\"conll04_test.json\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datum = train[0]\n",
    "tokens = torch.tensor(datum[0])\n",
    "entities = torch.tensor(datum[1])\n",
    "relations = torch.tensor(datum[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0911, grad_fn=<AddBackward0>)\n",
      "tensor(1.3064, grad_fn=<AddBackward0>)\n",
      "tensor(1.0823, grad_fn=<AddBackward0>)\n",
      "tensor(1.0197, grad_fn=<AddBackward0>)\n",
      "tensor(0.9641, grad_fn=<AddBackward0>)\n",
      "tensor(0.9125, grad_fn=<AddBackward0>)\n",
      "tensor(0.8636, grad_fn=<AddBackward0>)\n",
      "tensor(0.8164, grad_fn=<AddBackward0>)\n",
      "tensor(0.7703, grad_fn=<AddBackward0>)\n",
      "tensor(0.7250, grad_fn=<AddBackward0>)\n",
      "tensor(0.6802, grad_fn=<AddBackward0>)\n",
      "tensor(0.6363, grad_fn=<AddBackward0>)\n",
      "tensor(0.5933, grad_fn=<AddBackward0>)\n",
      "tensor(0.5518, grad_fn=<AddBackward0>)\n",
      "tensor(0.5122, grad_fn=<AddBackward0>)\n",
      "tensor(0.4746, grad_fn=<AddBackward0>)\n",
      "tensor(0.4393, grad_fn=<AddBackward0>)\n",
      "tensor(0.4062, grad_fn=<AddBackward0>)\n",
      "tensor(0.3752, grad_fn=<AddBackward0>)\n",
      "tensor(0.3463, grad_fn=<AddBackward0>)\n",
      "tensor(0.3194, grad_fn=<AddBackward0>)\n",
      "tensor(0.2943, grad_fn=<AddBackward0>)\n",
      "tensor(0.2710, grad_fn=<AddBackward0>)\n",
      "tensor(0.2492, grad_fn=<AddBackward0>)\n",
      "tensor(0.2289, grad_fn=<AddBackward0>)\n",
      "tensor(0.2098, grad_fn=<AddBackward0>)\n",
      "tensor(0.1920, grad_fn=<AddBackward0>)\n",
      "tensor(0.1755, grad_fn=<AddBackward0>)\n",
      "tensor(0.1603, grad_fn=<AddBackward0>)\n",
      "tensor(0.1465, grad_fn=<AddBackward0>)\n",
      "tensor(0.1339, grad_fn=<AddBackward0>)\n",
      "tensor(0.1227, grad_fn=<AddBackward0>)\n",
      "tensor(0.1126, grad_fn=<AddBackward0>)\n",
      "tensor(0.1036, grad_fn=<AddBackward0>)\n",
      "tensor(0.0955, grad_fn=<AddBackward0>)\n",
      "tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "tensor(0.0665, grad_fn=<AddBackward0>)\n",
      "tensor(0.0623, grad_fn=<AddBackward0>)\n",
      "tensor(0.0586, grad_fn=<AddBackward0>)\n",
      "tensor(0.0552, grad_fn=<AddBackward0>)\n",
      "tensor(0.0521, grad_fn=<AddBackward0>)\n",
      "tensor(0.0493, grad_fn=<AddBackward0>)\n",
      "tensor(0.0467, grad_fn=<AddBackward0>)\n",
      "tensor(0.0444, grad_fn=<AddBackward0>)\n",
      "tensor(0.0422, grad_fn=<AddBackward0>)\n",
      "tensor(0.0402, grad_fn=<AddBackward0>)\n",
      "tensor(0.0384, grad_fn=<AddBackward0>)\n",
      "tensor(0.0367, grad_fn=<AddBackward0>)\n",
      "tensor(0.0352, grad_fn=<AddBackward0>)\n",
      "tensor(0.0337, grad_fn=<AddBackward0>)\n",
      "tensor(0.0324, grad_fn=<AddBackward0>)\n",
      "tensor(0.0311, grad_fn=<AddBackward0>)\n",
      "tensor(0.0299, grad_fn=<AddBackward0>)\n",
      "tensor(0.0288, grad_fn=<AddBackward0>)\n",
      "tensor(0.0278, grad_fn=<AddBackward0>)\n",
      "tensor(0.0268, grad_fn=<AddBackward0>)\n",
      "tensor(0.0259, grad_fn=<AddBackward0>)\n",
      "tensor(0.0251, grad_fn=<AddBackward0>)\n",
      "tensor(0.0242, grad_fn=<AddBackward0>)\n",
      "tensor(0.0235, grad_fn=<AddBackward0>)\n",
      "tensor(0.0228, grad_fn=<AddBackward0>)\n",
      "tensor(0.0221, grad_fn=<AddBackward0>)\n",
      "tensor(0.0214, grad_fn=<AddBackward0>)\n",
      "tensor(0.0208, grad_fn=<AddBackward0>)\n",
      "tensor(0.0202, grad_fn=<AddBackward0>)\n",
      "tensor(0.0197, grad_fn=<AddBackward0>)\n",
      "tensor(0.0191, grad_fn=<AddBackward0>)\n",
      "tensor(0.0186, grad_fn=<AddBackward0>)\n",
      "tensor(0.0182, grad_fn=<AddBackward0>)\n",
      "tensor(0.0177, grad_fn=<AddBackward0>)\n",
      "tensor(0.0173, grad_fn=<AddBackward0>)\n",
      "tensor(0.0168, grad_fn=<AddBackward0>)\n",
      "tensor(0.0164, grad_fn=<AddBackward0>)\n",
      "tensor(0.0161, grad_fn=<AddBackward0>)\n",
      "tensor(0.0157, grad_fn=<AddBackward0>)\n",
      "tensor(0.0153, grad_fn=<AddBackward0>)\n",
      "tensor(0.0150, grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, grad_fn=<AddBackward0>)\n",
      "tensor(0.0144, grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, grad_fn=<AddBackward0>)\n",
      "tensor(0.0132, grad_fn=<AddBackward0>)\n",
      "tensor(0.0130, grad_fn=<AddBackward0>)\n",
      "tensor(0.0127, grad_fn=<AddBackward0>)\n",
      "tensor(0.0125, grad_fn=<AddBackward0>)\n",
      "tensor(0.0122, grad_fn=<AddBackward0>)\n",
      "tensor(0.0120, grad_fn=<AddBackward0>)\n",
      "tensor(0.0118, grad_fn=<AddBackward0>)\n",
      "tensor(0.0116, grad_fn=<AddBackward0>)\n",
      "tensor(0.0114, grad_fn=<AddBackward0>)\n",
      "tensor(0.0112, grad_fn=<AddBackward0>)\n",
      "tensor(0.0110, grad_fn=<AddBackward0>)\n",
      "tensor(0.0108, grad_fn=<AddBackward0>)\n",
      "tensor(0.0106, grad_fn=<AddBackward0>)\n",
      "tensor(0.0104, grad_fn=<AddBackward0>)\n",
      "tensor(0.0103, grad_fn=<AddBackward0>)\n",
      "tensor(0.0101, grad_fn=<AddBackward0>)\n",
      "tensor(0.0099, grad_fn=<AddBackward0>)\n",
      "tensor(0.0098, grad_fn=<AddBackward0>)\n",
      "tensor(0.0096, grad_fn=<AddBackward0>)\n",
      "tensor(0.0095, grad_fn=<AddBackward0>)\n",
      "tensor(0.0094, grad_fn=<AddBackward0>)\n",
      "tensor(0.0092, grad_fn=<AddBackward0>)\n",
      "tensor(0.0091, grad_fn=<AddBackward0>)\n",
      "tensor(0.0089, grad_fn=<AddBackward0>)\n",
      "tensor(0.0088, grad_fn=<AddBackward0>)\n",
      "tensor(0.0087, grad_fn=<AddBackward0>)\n",
      "tensor(0.0086, grad_fn=<AddBackward0>)\n",
      "tensor(0.0085, grad_fn=<AddBackward0>)\n",
      "tensor(0.0083, grad_fn=<AddBackward0>)\n",
      "tensor(0.0082, grad_fn=<AddBackward0>)\n",
      "tensor(0.0081, grad_fn=<AddBackward0>)\n",
      "tensor(0.0080, grad_fn=<AddBackward0>)\n",
      "tensor(0.0079, grad_fn=<AddBackward0>)\n",
      "tensor(0.0078, grad_fn=<AddBackward0>)\n",
      "tensor(0.0077, grad_fn=<AddBackward0>)\n",
      "tensor(0.0076, grad_fn=<AddBackward0>)\n",
      "tensor(0.0075, grad_fn=<AddBackward0>)\n",
      "tensor(0.0074, grad_fn=<AddBackward0>)\n",
      "tensor(0.0073, grad_fn=<AddBackward0>)\n",
      "tensor(0.0072, grad_fn=<AddBackward0>)\n",
      "tensor(0.0072, grad_fn=<AddBackward0>)\n",
      "tensor(0.0071, grad_fn=<AddBackward0>)\n",
      "tensor(0.0070, grad_fn=<AddBackward0>)\n",
      "tensor(0.0069, grad_fn=<AddBackward0>)\n",
      "tensor(0.0068, grad_fn=<AddBackward0>)\n",
      "tensor(0.0068, grad_fn=<AddBackward0>)\n",
      "tensor(0.0067, grad_fn=<AddBackward0>)\n",
      "tensor(0.0066, grad_fn=<AddBackward0>)\n",
      "tensor(0.0065, grad_fn=<AddBackward0>)\n",
      "tensor(0.0065, grad_fn=<AddBackward0>)\n",
      "tensor(0.0064, grad_fn=<AddBackward0>)\n",
      "tensor(0.0063, grad_fn=<AddBackward0>)\n",
      "tensor(0.0063, grad_fn=<AddBackward0>)\n",
      "tensor(0.0062, grad_fn=<AddBackward0>)\n",
      "tensor(0.0061, grad_fn=<AddBackward0>)\n",
      "tensor(0.0061, grad_fn=<AddBackward0>)\n",
      "tensor(0.0060, grad_fn=<AddBackward0>)\n",
      "tensor(0.0059, grad_fn=<AddBackward0>)\n",
      "tensor(0.0059, grad_fn=<AddBackward0>)\n",
      "tensor(0.0058, grad_fn=<AddBackward0>)\n",
      "tensor(0.0058, grad_fn=<AddBackward0>)\n",
      "tensor(0.0057, grad_fn=<AddBackward0>)\n",
      "tensor(0.0056, grad_fn=<AddBackward0>)\n",
      "tensor(0.0056, grad_fn=<AddBackward0>)\n",
      "tensor(0.0055, grad_fn=<AddBackward0>)\n",
      "tensor(0.0055, grad_fn=<AddBackward0>)\n",
      "tensor(0.0054, grad_fn=<AddBackward0>)\n",
      "tensor(0.0054, grad_fn=<AddBackward0>)\n",
      "tensor(0.0053, grad_fn=<AddBackward0>)\n",
      "tensor(0.0053, grad_fn=<AddBackward0>)\n",
      "tensor(0.0052, grad_fn=<AddBackward0>)\n",
      "tensor(0.0052, grad_fn=<AddBackward0>)\n",
      "tensor(0.0051, grad_fn=<AddBackward0>)\n",
      "tensor(0.0051, grad_fn=<AddBackward0>)\n",
      "tensor(0.0051, grad_fn=<AddBackward0>)\n",
      "tensor(0.0050, grad_fn=<AddBackward0>)\n",
      "tensor(0.0050, grad_fn=<AddBackward0>)\n",
      "tensor(0.0049, grad_fn=<AddBackward0>)\n",
      "tensor(0.0049, grad_fn=<AddBackward0>)\n",
      "tensor(0.0048, grad_fn=<AddBackward0>)\n",
      "tensor(0.0048, grad_fn=<AddBackward0>)\n",
      "tensor(0.0048, grad_fn=<AddBackward0>)\n",
      "tensor(0.0047, grad_fn=<AddBackward0>)\n",
      "tensor(0.0047, grad_fn=<AddBackward0>)\n",
      "tensor(0.0046, grad_fn=<AddBackward0>)\n",
      "tensor(0.0046, grad_fn=<AddBackward0>)\n",
      "tensor(0.0046, grad_fn=<AddBackward0>)\n",
      "tensor(0.0045, grad_fn=<AddBackward0>)\n",
      "tensor(0.0045, grad_fn=<AddBackward0>)\n",
      "tensor(0.0045, grad_fn=<AddBackward0>)\n",
      "tensor(0.0044, grad_fn=<AddBackward0>)\n",
      "tensor(0.0044, grad_fn=<AddBackward0>)\n",
      "tensor(0.0044, grad_fn=<AddBackward0>)\n",
      "tensor(0.0043, grad_fn=<AddBackward0>)\n",
      "tensor(0.0043, grad_fn=<AddBackward0>)\n",
      "tensor(0.0043, grad_fn=<AddBackward0>)\n",
      "tensor(0.0042, grad_fn=<AddBackward0>)\n",
      "tensor(0.0042, grad_fn=<AddBackward0>)\n",
      "tensor(0.0042, grad_fn=<AddBackward0>)\n",
      "tensor(0.0041, grad_fn=<AddBackward0>)\n",
      "tensor(0.0041, grad_fn=<AddBackward0>)\n",
      "tensor(0.0041, grad_fn=<AddBackward0>)\n",
      "tensor(0.0040, grad_fn=<AddBackward0>)\n",
      "tensor(0.0040, grad_fn=<AddBackward0>)\n",
      "tensor(0.0040, grad_fn=<AddBackward0>)\n",
      "tensor(0.0039, grad_fn=<AddBackward0>)\n",
      "tensor(0.0039, grad_fn=<AddBackward0>)\n",
      "tensor(0.0039, grad_fn=<AddBackward0>)\n",
      "tensor(0.0039, grad_fn=<AddBackward0>)\n",
      "tensor(0.0038, grad_fn=<AddBackward0>)\n",
      "tensor(0.0038, grad_fn=<AddBackward0>)\n",
      "tensor(0.0038, grad_fn=<AddBackward0>)\n",
      "tensor(0.0038, grad_fn=<AddBackward0>)\n",
      "tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "tensor(0.0034, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "tensor(0.0033, grad_fn=<AddBackward0>)\n",
      "tensor(0.0033, grad_fn=<AddBackward0>)\n",
      "tensor(0.0033, grad_fn=<AddBackward0>)\n",
      "tensor(0.0033, grad_fn=<AddBackward0>)\n",
      "tensor(0.0033, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from pytorch_constraints.constraint import constraint\n",
    "# from pytorch_constraints.brute_force_solver import *\n",
    "# from pytorch_constraints.sampling_solver import *\n",
    "# from pytorch_constraints.tnorm_solver import TNormLogicSolver\n",
    "\n",
    "# Models\n",
    "ner = NER_Net(vocab_size=len(vocab), num_classes=len(ENTITY_TO_ID))\n",
    "re = RE_Net(vocab_size=len(vocab), num_classes=len(REL_TO_ID))\n",
    "\n",
    "# Optimization\n",
    "opt = torch.optim.SGD(list(ner.parameters()) + list(re.parameters()), lr=1.0)\n",
    "\n",
    "# # Plotting\n",
    "# plot = PlotHelper()\n",
    "# plot_loss = PlotHelper()\n",
    "\n",
    "num_samples = 100\n",
    "for i in range(500):\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    ner_logits = ner(tokens)\n",
    "    ner_logits = ner_logits.view(-1, ner_logits.shape[2])\n",
    "    \n",
    "    re_logits = re(tokens)\n",
    "    re_logits = re_logits.view(-1, re_logits.shape[2])\n",
    "    \n",
    "    \n",
    "    ner_loss = F.cross_entropy(ner_logits, entities.view(-1))\n",
    "    re_loss = F.cross_entropy(re_logits, relations.view(-1))\n",
    "    loss = ner_loss + re_loss\n",
    "    \n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    print(loss)\n",
    "    \n",
    "#     y_prob = torch.softmax(y_logit, dim=-1)\n",
    "#     plot.add(y0=y_prob[0,1].data, y1=y_prob[1,1].data, y2=y_prob[2,1].data)\n",
    "#     plot_loss.add(oloss=oloss.data, closs=closs.data, loss=loss.data)\n",
    "#     opt.step()\n",
    "\n",
    "# plot.show()\n",
    "# plot_loss.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.softmax(re(tokens).view(-1, 11), dim=-1), dim=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
