{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "class PlotHelper():\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self._f = None\n",
    "        self._ax = None\n",
    "        self.kvals = defaultdict(list)\n",
    "\n",
    "    def add(self, **kval):\n",
    "        for k, v in kval.items():\n",
    "            self.kvals[k].append(v)\n",
    "\n",
    "    @property\n",
    "    def fig(self):\n",
    "        if self._f is None:\n",
    "            self.new()\n",
    "        return self._f\n",
    "\n",
    "    @property\n",
    "    def ax(self):\n",
    "        if self._ax is None:\n",
    "            self.new()\n",
    "        return self._ax\n",
    "\n",
    "    def new(self):\n",
    "        self._f, self._ax = plt.subplots(1,1)\n",
    "        plt.ion()\n",
    "        self.fig.show()\n",
    "\n",
    "    def show(self):\n",
    "        names = []\n",
    "        self.ax.clear()\n",
    "        for k, v in self.kvals.items():\n",
    "            names.append(k)\n",
    "            self.ax.plot(v)\n",
    "        self.ax.legend(names)\n",
    "        self.fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_balanced_subset(dataset, n_per_class):\n",
    "    classes = dataset.targets.unique()\n",
    "    indices = [(dataset.targets == c).nonzero(as_tuple=False) [:n_per_class] for c in classes]\n",
    "    indices = torch.stack(indices).flatten()\n",
    "    return torch.utils.data.Subset(dataset, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch, cons=None, plot_loss=None):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        output = output.reshape(10,10)\n",
    "        \n",
    "        loss = F.cross_entropy(output[:1], target)\n",
    "        closs = cons(output) if cons else torch.tensor(0).to(device)\n",
    "        \n",
    "        loss += closs\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Logging\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for data, target in test_loader:\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            output = output.reshape(10,10)\n",
    "            # sum up batch loss\n",
    "            test_loss += F.cross_entropy(output[:1], target, reduction='sum').item()\n",
    "            \n",
    "            # get the index of the max log-probability\n",
    "            pred = output[:1].argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from pytorch_constraints.constraint import constraint\n",
    "from pytorch_constraints.sampling_solver import WeightedSamplingSolver\n",
    "\n",
    "def only_one(x):\n",
    "    \n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x)\n",
    "        \n",
    "    x = torch.zeros(10).scatter_(0, x, 1.)\n",
    "    return sum(x) == 1\n",
    "\n",
    "class Args:\n",
    "    batch_size = 1\n",
    "    test_batch_size = 1000\n",
    "    epochs = 1\n",
    "    lr = 1.0\n",
    "    gamma = 0.7\n",
    "    seed = 1\n",
    "    log_interval = 10\n",
    "    use_cuda = False\n",
    "    n_per_class = 100\n",
    "    \n",
    "# Plotting\n",
    "plot_loss = PlotHelper()\n",
    "    \n",
    "args = Args()\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if args.use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'batch_size': args.batch_size}\n",
    "if args.use_cuda:\n",
    "    kwargs.update({'num_workers': 1,\n",
    "                   'pin_memory': True,\n",
    "                   'shuffle': True},\n",
    "                 )\n",
    "\n",
    "# Prepare dataset transformations\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "# Load train and test splits\n",
    "train_split = datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transform)\n",
    "test_split = datasets.MNIST('../data', train=False,\n",
    "                   transform=transform)\n",
    "\n",
    "# Sample a balanced subset of the train set\n",
    "train_split = sample_balanced_subset(train_split, args.n_per_class)\n",
    "\n",
    "# Create train, validation and test data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_split,**kwargs)\n",
    "test_loader  = torch.utils.data.DataLoader(test_split, **kwargs)\n",
    "\n",
    "# Constraint to be applied on unlabeled data\n",
    "only_one_constraint = constraint(only_one, WeightedSamplingSolver(num_samples=100))\n",
    "\n",
    "# Move model to correct device\n",
    "model = Net().to(device)\n",
    "\n",
    "# Set up optimizers\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0., grad_fn=<NegBackward>)\n",
      "tensor(2.3842e-07, grad_fn=<NegBackward>)\n",
      "tensor(0.0010, grad_fn=<NegBackward>)\n",
      "tensor(0.0355, grad_fn=<NegBackward>)\n",
      "tensor(8.3681e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0516, grad_fn=<NegBackward>)\n",
      "tensor(2.8133e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.1261, grad_fn=<NegBackward>)\n",
      "tensor(0.0279, grad_fn=<NegBackward>)\n",
      "tensor(1.0165, grad_fn=<NegBackward>)\n",
      "tensor(0.0007, grad_fn=<NegBackward>)\n",
      "tensor(0.0190, grad_fn=<NegBackward>)\n",
      "tensor(1.3947e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0158, grad_fn=<NegBackward>)\n",
      "tensor(0.1750, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.2606, grad_fn=<NegBackward>)\n",
      "tensor(0.0010, grad_fn=<NegBackward>)\n",
      "tensor(0.0046, grad_fn=<NegBackward>)\n",
      "tensor(0.0009, grad_fn=<NegBackward>)\n",
      "tensor(0.0024, grad_fn=<NegBackward>)\n",
      "tensor(0.0031, grad_fn=<NegBackward>)\n",
      "tensor(0.0027, grad_fn=<NegBackward>)\n",
      "tensor(0.0011, grad_fn=<NegBackward>)\n",
      "tensor(0.0144, grad_fn=<NegBackward>)\n",
      "tensor(6.9973e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0026, grad_fn=<NegBackward>)\n",
      "tensor(0.0075, grad_fn=<NegBackward>)\n",
      "tensor(0.0039, grad_fn=<NegBackward>)\n",
      "tensor(0.0388, grad_fn=<NegBackward>)\n",
      "tensor(0.0046, grad_fn=<NegBackward>)\n",
      "tensor(0.0027, grad_fn=<NegBackward>)\n",
      "tensor(0.0094, grad_fn=<NegBackward>)\n",
      "tensor(0.0053, grad_fn=<NegBackward>)\n",
      "tensor(0.0477, grad_fn=<NegBackward>)\n",
      "tensor(8.1893e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0210, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(3.2067e-05, grad_fn=<NegBackward>)\n",
      "tensor(9.9773e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "tensor(0.0007, grad_fn=<NegBackward>)\n",
      "tensor(1.3947e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0026, grad_fn=<NegBackward>)\n",
      "tensor(0.0193, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(8.4635e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0035, grad_fn=<NegBackward>)\n",
      "tensor(0.0099, grad_fn=<NegBackward>)\n",
      "tensor(0.0299, grad_fn=<NegBackward>)\n",
      "tensor(0.0035, grad_fn=<NegBackward>)\n",
      "tensor(0.0022, grad_fn=<NegBackward>)\n",
      "tensor(0.0081, grad_fn=<NegBackward>)\n",
      "tensor(8.9641e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0025, grad_fn=<NegBackward>)\n",
      "tensor(0.0007, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(0.0018, grad_fn=<NegBackward>)\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "tensor(0.0012, grad_fn=<NegBackward>)\n",
      "tensor(0.0006, grad_fn=<NegBackward>)\n",
      "tensor(0.0186, grad_fn=<NegBackward>)\n",
      "tensor(0.0007, grad_fn=<NegBackward>)\n",
      "tensor(1.6093e-05, grad_fn=<NegBackward>)\n",
      "tensor(1.3113e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0017, grad_fn=<NegBackward>)\n",
      "tensor(0.0010, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(0.0012, grad_fn=<NegBackward>)\n",
      "tensor(0.0026, grad_fn=<NegBackward>)\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(0.0014, grad_fn=<NegBackward>)\n",
      "tensor(6.1629e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0006, grad_fn=<NegBackward>)\n",
      "tensor(0.0165, grad_fn=<NegBackward>)\n",
      "tensor(0.0008, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "tensor(0.0014, grad_fn=<NegBackward>)\n",
      "tensor(4.8875e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0096, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(0.0009, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0061, grad_fn=<NegBackward>)\n",
      "tensor(0.0007, grad_fn=<NegBackward>)\n",
      "tensor(0.0058, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "tensor(3.9338e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0007, grad_fn=<NegBackward>)\n",
      "tensor(0.0031, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0066, grad_fn=<NegBackward>)\n",
      "tensor(3.8504e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "tensor(0.0011, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(2.1815e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(0.0045, grad_fn=<NegBackward>)\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "tensor(0.0006, grad_fn=<NegBackward>)\n",
      "tensor(0.0006, grad_fn=<NegBackward>)\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "tensor(0.0014, grad_fn=<NegBackward>)\n",
      "tensor(0.0009, grad_fn=<NegBackward>)\n",
      "tensor(0.0018, grad_fn=<NegBackward>)\n",
      "tensor(0.0167, grad_fn=<NegBackward>)\n",
      "tensor(0.0014, grad_fn=<NegBackward>)\n",
      "tensor(0.0022, grad_fn=<NegBackward>)\n",
      "tensor(9.1668e-05, grad_fn=<NegBackward>)\n",
      "tensor(4.7684e-06, grad_fn=<NegBackward>)\n",
      "tensor(0.0074, grad_fn=<NegBackward>)\n",
      "tensor(0.0057, grad_fn=<NegBackward>)\n",
      "tensor(0.0006, grad_fn=<NegBackward>)\n",
      "tensor(3.6239e-05, grad_fn=<NegBackward>)\n",
      "tensor(6.6040e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0015, grad_fn=<NegBackward>)\n",
      "tensor(0.0013, grad_fn=<NegBackward>)\n",
      "tensor(0.0009, grad_fn=<NegBackward>)\n",
      "tensor(0.0012, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(1.2636e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0198, grad_fn=<NegBackward>)\n",
      "tensor(0.0008, grad_fn=<NegBackward>)\n",
      "tensor(4.4941e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(0.0025, grad_fn=<NegBackward>)\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "tensor(5.7696e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0015, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(0.0007, grad_fn=<NegBackward>)\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "tensor(8.7022e-06, grad_fn=<NegBackward>)\n",
      "tensor(7.8317e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "tensor(0.0023, grad_fn=<NegBackward>)\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "tensor(0.0007, grad_fn=<NegBackward>)\n",
      "tensor(0.0028, grad_fn=<NegBackward>)\n",
      "tensor(6.0318e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(4.5299e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0008, grad_fn=<NegBackward>)\n",
      "tensor(9.4171e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "tensor(4.8040e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(1.0729e-06, grad_fn=<NegBackward>)\n",
      "tensor(0.0189, grad_fn=<NegBackward>)\n",
      "tensor(0.0920, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(0.0018, grad_fn=<NegBackward>)\n",
      "tensor(0.0006, grad_fn=<NegBackward>)\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "tensor(0.0048, grad_fn=<NegBackward>)\n",
      "tensor(0.0008, grad_fn=<NegBackward>)\n",
      "tensor(0.0008, grad_fn=<NegBackward>)\n",
      "tensor(0.0007, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(6.8185e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "tensor(1.4543e-05, grad_fn=<NegBackward>)\n",
      "tensor(6.0797e-06, grad_fn=<NegBackward>)\n",
      "tensor(2.1577e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "tensor(0.0006, grad_fn=<NegBackward>)\n",
      "tensor(0.0017, grad_fn=<NegBackward>)\n",
      "tensor(0.0072, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0008, grad_fn=<NegBackward>)\n",
      "tensor(5.1974e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0010, grad_fn=<NegBackward>)\n",
      "tensor(5.4477e-05, grad_fn=<NegBackward>)\n",
      "tensor(6.6397e-05, grad_fn=<NegBackward>)\n",
      "tensor(8.4277e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0009, grad_fn=<NegBackward>)\n",
      "tensor(0.0008, grad_fn=<NegBackward>)\n",
      "tensor(0.0006, grad_fn=<NegBackward>)\n",
      "tensor(9.5367e-06, grad_fn=<NegBackward>)\n",
      "tensor(3.8385e-05, grad_fn=<NegBackward>)\n",
      "tensor(5.8768e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "tensor(8.7853e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "tensor(5.9126e-05, grad_fn=<NegBackward>)\n",
      "tensor(8.2370e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0007, grad_fn=<NegBackward>)\n",
      "tensor(2.6106e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0006, grad_fn=<NegBackward>)\n",
      "tensor(6.2583e-05, grad_fn=<NegBackward>)\n",
      "tensor(7.8437e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "tensor(1.8596e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.4741e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0056, grad_fn=<NegBackward>)\n",
      "tensor(3.7550e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(3.4928e-05, grad_fn=<NegBackward>)\n",
      "tensor(4.5299e-06, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(1.2278e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(0.0053, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(8.4635e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(9.6912e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(1.6332e-05, grad_fn=<NegBackward>)\n",
      "tensor(5.6027e-05, grad_fn=<NegBackward>)\n",
      "tensor(9.4175e-06, grad_fn=<NegBackward>)\n",
      "tensor(0.0011, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(2.9802e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0012, grad_fn=<NegBackward>)\n",
      "tensor(0.0008, grad_fn=<NegBackward>)\n",
      "tensor(2.7656e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0033, grad_fn=<NegBackward>)\n",
      "tensor(4.0054e-05, grad_fn=<NegBackward>)\n",
      "tensor(3.2067e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(4.8279e-05, grad_fn=<NegBackward>)\n",
      "tensor(6.4252e-05, grad_fn=<NegBackward>)\n",
      "tensor(3.8147e-06, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(4.4583e-05, grad_fn=<NegBackward>)\n",
      "tensor(7.7245e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(5.2332e-05, grad_fn=<NegBackward>)\n",
      "tensor(7.1525e-06, grad_fn=<NegBackward>)\n",
      "tensor(2.8610e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.4318e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(5.9604e-06, grad_fn=<NegBackward>)\n",
      "tensor(8.1062e-06, grad_fn=<NegBackward>)\n",
      "tensor(5.8768e-05, grad_fn=<NegBackward>)\n",
      "tensor(1.7166e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(4.7684e-06, grad_fn=<NegBackward>)\n",
      "tensor(0.0006, grad_fn=<NegBackward>)\n",
      "tensor(1.4782e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(3.0636e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(0.0019, grad_fn=<NegBackward>)\n",
      "tensor(1.5259e-05, grad_fn=<NegBackward>)\n",
      "tensor(8.2254e-06, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(3.3974e-05, grad_fn=<NegBackward>)\n",
      "tensor(5.2570e-05, grad_fn=<NegBackward>)\n",
      "tensor(3.7789e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(8.9407e-06, grad_fn=<NegBackward>)\n",
      "tensor(1.8596e-05, grad_fn=<NegBackward>)\n",
      "tensor(1.8000e-05, grad_fn=<NegBackward>)\n",
      "tensor(4.1007e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(2.1458e-06, grad_fn=<NegBackward>)\n",
      "tensor(1.1325e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(1.2755e-05, grad_fn=<NegBackward>)\n",
      "tensor(6.6159e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(4.6252e-05, grad_fn=<NegBackward>)\n",
      "tensor(7.5102e-06, grad_fn=<NegBackward>)\n",
      "tensor(1.6928e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0006, grad_fn=<NegBackward>)\n",
      "tensor(1.2517e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(3.1113e-05, grad_fn=<NegBackward>)\n",
      "tensor(9.9535e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(3.5405e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.7895e-05, grad_fn=<NegBackward>)\n",
      "tensor(8.6423e-05, grad_fn=<NegBackward>)\n",
      "tensor(4.1603e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0006, grad_fn=<NegBackward>)\n",
      "tensor(5.2332e-05, grad_fn=<NegBackward>)\n",
      "tensor(4.1126e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(7.4384e-05, grad_fn=<NegBackward>)\n",
      "tensor(7.1285e-05, grad_fn=<NegBackward>)\n",
      "tensor(7.9152e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(2.5153e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(2.6106e-05, grad_fn=<NegBackward>)\n",
      "tensor(1.8596e-05, grad_fn=<NegBackward>)\n",
      "tensor(5.2689e-05, grad_fn=<NegBackward>)\n",
      "tensor(3.4093e-05, grad_fn=<NegBackward>)\n",
      "tensor(1.5497e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.3126e-05, grad_fn=<NegBackward>)\n",
      "tensor(8.8926e-05, grad_fn=<NegBackward>)\n",
      "tensor(5.9604e-06, grad_fn=<NegBackward>)\n",
      "tensor(0.0006, grad_fn=<NegBackward>)\n",
      "tensor(1.0490e-05, grad_fn=<NegBackward>)\n",
      "tensor(9.6559e-06, grad_fn=<NegBackward>)\n",
      "tensor(9.0357e-05, grad_fn=<NegBackward>)\n",
      "tensor(9.3456e-05, grad_fn=<NegBackward>)\n",
      "tensor(1.4543e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0006, grad_fn=<NegBackward>)\n",
      "tensor(6.8543e-05, grad_fn=<NegBackward>)\n",
      "tensor(8.2966e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(3.4212e-05, grad_fn=<NegBackward>)\n",
      "tensor(1.8835e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(4.7921e-05, grad_fn=<NegBackward>)\n",
      "tensor(3.4212e-05, grad_fn=<NegBackward>)\n",
      "tensor(3.9339e-06, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(5.5192e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(3.9577e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "tensor(0.0008, grad_fn=<NegBackward>)\n",
      "tensor(4.5179e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0010, grad_fn=<NegBackward>)\n",
      "tensor(4.8279e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(1.2159e-05, grad_fn=<NegBackward>)\n",
      "tensor(5.0543e-05, grad_fn=<NegBackward>)\n",
      "tensor(6.9141e-06, grad_fn=<NegBackward>)\n",
      "tensor(5.0543e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.0265e-05, grad_fn=<NegBackward>)\n",
      "tensor(7.8198e-05, grad_fn=<NegBackward>)\n",
      "tensor(1.2636e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(1.0133e-05, grad_fn=<NegBackward>)\n",
      "tensor(1.6928e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.6822e-05, grad_fn=<NegBackward>)\n",
      "tensor(1.7404e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.1338e-05, grad_fn=<NegBackward>)\n",
      "tensor(9.5005e-05, grad_fn=<NegBackward>)\n",
      "tensor(7.5457e-05, grad_fn=<NegBackward>)\n",
      "tensor(4.1723e-06, grad_fn=<NegBackward>)\n",
      "tensor(6.7113e-05, grad_fn=<NegBackward>)\n",
      "tensor(3.4570e-05, grad_fn=<NegBackward>)\n",
      "tensor(4.2915e-06, grad_fn=<NegBackward>)\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "tensor(1.8477e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.4795e-05, grad_fn=<NegBackward>)\n",
      "tensor(6.6159e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(3.7193e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.6345e-05, grad_fn=<NegBackward>)\n",
      "tensor(6.0676e-05, grad_fn=<NegBackward>)\n",
      "tensor(4.8398e-05, grad_fn=<NegBackward>)\n",
      "tensor(7.7125e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0009, grad_fn=<NegBackward>)\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "tensor(9.5367e-06, grad_fn=<NegBackward>)\n",
      "tensor(1.0490e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0008, grad_fn=<NegBackward>)\n",
      "tensor(1.8477e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.3842e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.6226e-05, grad_fn=<NegBackward>)\n",
      "tensor(9.8104e-05, grad_fn=<NegBackward>)\n",
      "tensor(6.1989e-06, grad_fn=<NegBackward>)\n",
      "tensor(1.7881e-05, grad_fn=<NegBackward>)\n",
      "tensor(5.9245e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(1.8835e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.6703e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(1.4305e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(2.9563e-05, grad_fn=<NegBackward>)\n",
      "tensor(3.4928e-05, grad_fn=<NegBackward>)\n",
      "tensor(6.1391e-05, grad_fn=<NegBackward>)\n",
      "tensor(3.8504e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(1.3590e-05, grad_fn=<NegBackward>)\n",
      "tensor(7.2596e-05, grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5034e-06, grad_fn=<NegBackward>)\n",
      "tensor(7.3549e-05, grad_fn=<NegBackward>)\n",
      "tensor(5.9126e-05, grad_fn=<NegBackward>)\n",
      "tensor(3.9100e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.0027e-05, grad_fn=<NegBackward>)\n",
      "tensor(1.1563e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(3.9100e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(2.3961e-05, grad_fn=<NegBackward>)\n",
      "tensor(1.7404e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(5.0186e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.0027e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.2173e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.3961e-05, grad_fn=<NegBackward>)\n",
      "tensor(6.0797e-06, grad_fn=<NegBackward>)\n",
      "tensor(4.2438e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(0.0058, grad_fn=<NegBackward>)\n",
      "tensor(3.7193e-05, grad_fn=<NegBackward>)\n",
      "tensor(4.2318e-05, grad_fn=<NegBackward>)\n",
      "tensor(9.5601e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0007, grad_fn=<NegBackward>)\n",
      "tensor(8.3205e-05, grad_fn=<NegBackward>)\n",
      "tensor(1.6928e-05, grad_fn=<NegBackward>)\n",
      "tensor(8.8807e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(1.3590e-05, grad_fn=<NegBackward>)\n",
      "tensor(7.7245e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "tensor(1.4067e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "tensor(5.4120e-05, grad_fn=<NegBackward>)\n",
      "tensor(7.9986e-05, grad_fn=<NegBackward>)\n",
      "tensor(3.0994e-05, grad_fn=<NegBackward>)\n",
      "tensor(8.4638e-06, grad_fn=<NegBackward>)\n",
      "tensor(3.8027e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(3.3616e-05, grad_fn=<NegBackward>)\n",
      "tensor(6.2106e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0007, grad_fn=<NegBackward>)\n",
      "tensor(3.2067e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.7537e-05, grad_fn=<NegBackward>)\n",
      "tensor(4.0650e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.5034e-06, grad_fn=<NegBackward>)\n",
      "tensor(9.7151e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "tensor(5.6742e-05, grad_fn=<NegBackward>)\n",
      "tensor(1.5855e-05, grad_fn=<NegBackward>)\n",
      "tensor(3.8147e-06, grad_fn=<NegBackward>)\n",
      "tensor(2.0385e-05, grad_fn=<NegBackward>)\n",
      "tensor(6.7949e-06, grad_fn=<NegBackward>)\n",
      "tensor(9.0476e-05, grad_fn=<NegBackward>)\n",
      "tensor(1.7404e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.6941e-05, grad_fn=<NegBackward>)\n",
      "tensor(6.1989e-06, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(2.9087e-05, grad_fn=<NegBackward>)\n",
      "tensor(3.6120e-05, grad_fn=<NegBackward>)\n",
      "tensor(8.0940e-05, grad_fn=<NegBackward>)\n",
      "tensor(6.0676e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(2.3603e-05, grad_fn=<NegBackward>)\n",
      "tensor(4.3987e-05, grad_fn=<NegBackward>)\n",
      "tensor(4.6729e-05, grad_fn=<NegBackward>)\n",
      "tensor(2.7418e-06, grad_fn=<NegBackward>)\n",
      "tensor(1.5616e-05, grad_fn=<NegBackward>)\n",
      "tensor(1.2755e-05, grad_fn=<NegBackward>)\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "tensor(4.6492e-06, grad_fn=<NegBackward>)\n",
      "tensor(2.5034e-06, grad_fn=<NegBackward>)\n",
      "tensor(0.0006, grad_fn=<NegBackward>)\n",
      "tensor(3.3140e-05, grad_fn=<NegBackward>)\n",
      "tensor(9.0476e-05, grad_fn=<NegBackward>)\n",
      "tensor(3.0279e-05, grad_fn=<NegBackward>)\n",
      "tensor(6.1629e-05, grad_fn=<NegBackward>)\n",
      "tensor(8.2254e-06, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "for data, target in train_loader:\n",
    "    break\n",
    "\n",
    "for _ in range(500):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(data)\n",
    "    output = output.reshape(10,10)\n",
    "    \n",
    "    loss = F.cross_entropy(output[:1], target)\n",
    "    closs = only_one_constraint(output)\n",
    "    print(closs)\n",
    "    \n",
    "    loss += closs\n",
    "#     print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 7, 7, 2, 7, 6, 6, 4, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.softmax(output, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(1, args.epochs + 1):\n",
    "#     train(args, model, device, train_loader, optimizer, epoch, only_one_constraint, plot_loss)\n",
    "#     test(model, device, test_loader)\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"..\")\n",
    "\n",
    "# from pytorch_constraints.constraint import constraint\n",
    "# from pytorch_constraints.sampling_solver import WeightedSamplingSolver\n",
    "\n",
    "# def only_one(x):\n",
    "    \n",
    "#     if not torch.is_tensor(x):\n",
    "#         x = torch.tensor(x)\n",
    "        \n",
    "#     x = torch.zeros(10).scatter_(0, x, 1.)\n",
    "#     return sum(x) == 1\n",
    "\n",
    "# class Args:\n",
    "#     batch_size = 1\n",
    "#     test_batch_size = 1000\n",
    "#     epochs = 1\n",
    "#     lr = 1.0\n",
    "#     gamma = 0.7\n",
    "#     seed = 1\n",
    "#     log_interval = 10\n",
    "#     use_cuda = False\n",
    "#     n_per_class = 100\n",
    "    \n",
    "# # Plotting\n",
    "# plot_loss = PlotHelper()\n",
    "    \n",
    "# args = Args()\n",
    "# torch.manual_seed(args.seed)\n",
    "\n",
    "# device = torch.device(\"cuda\" if args.use_cuda else \"cpu\")\n",
    "\n",
    "# kwargs = {'batch_size': args.batch_size}\n",
    "# if args.use_cuda:\n",
    "#     kwargs.update({'num_workers': 1,\n",
    "#                    'pin_memory': True,\n",
    "#                    'shuffle': True},\n",
    "#                  )\n",
    "\n",
    "# # Prepare dataset transformations\n",
    "# transform=transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.1307,), (0.3081,))\n",
    "#     ])\n",
    "\n",
    "# # Load train and test splits\n",
    "# train_split = datasets.MNIST('../data', train=True, download=True,\n",
    "#                    transform=transform)\n",
    "# test_split = datasets.MNIST('../data', train=False,\n",
    "#                    transform=transform)\n",
    "\n",
    "# # Sample a balanced subset of the train set\n",
    "# train_split = sample_balanced_subset(train_split, args.n_per_class)\n",
    "\n",
    "# # Create train, validation and test data loaders\n",
    "# train_loader = torch.utils.data.DataLoader(train_split,**kwargs)\n",
    "# test_loader  = torch.utils.data.DataLoader(test_split, **kwargs)\n",
    "\n",
    "# # Constraint to be applied on unlabeled data\n",
    "# only_one_constraint = constraint(only_one, WeightedSamplingSolver())\n",
    "\n",
    "# # Move model to correct device\n",
    "# model = Net().to(device)\n",
    "\n",
    "# # Set up optimizers\n",
    "# optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "# scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "\n",
    "# for epoch in range(1, args.epochs + 1):\n",
    "#     train(args, model, device, train_loader, optimizer, epoch, only_one_constraint, plot_loss)\n",
    "#     test(model, device, test_loader)\n",
    "#     scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
