{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6x6 Sudoku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task considered in that of solving a 6x6 sudoku by means of imposing constraints on the predictions of the model during training. We do not enforce that the entire predicted sudoku be valid, but rather that every row, column and square have unique elements. If all such constraints are satisfied, we're guaranteed that the predicted sudoku is valid. This case study therefore provides an example of cases where it might be infeasible to enforce a constraint, in which case we can resort to breaking it down into simpler constraints which we can then simultaneously minimize during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "torch.manual_seed(4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by defining our model. As can be seen our model is just 3D tensor-- each cell in the 6x6 sudkoku can take on any of 6 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SudokuSolver(nn.Module):\n",
    "    def __init__(self, board_size):\n",
    "        super().__init__()\n",
    "        self.W = torch.nn.Parameter(torch.rand((1,6,6,6)))\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        \n",
    "        return self.W\n",
    "\n",
    "# auxiliary functions    \n",
    "def process_inputs(X):\n",
    "    \n",
    "    is_input = X.sum(dim=3, keepdim=True)\n",
    "    \n",
    "    X = X.view(X.size(0), -1)\n",
    "    is_input = is_input.view(is_input.size(0), -1)\n",
    "    \n",
    "    return is_input\n",
    "\n",
    "def show_sudoku(X):\n",
    "    return (torch.argmax(X, 1) + 1) * (X.sum(2).long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our input and target, and unpack them into 3D tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[0, 4, 1, 0, 3, 0],\n",
    "                  [0, 0, 3, 5, 1, 0],\n",
    "                  [4, 1, 0, 0, 2, 5],\n",
    "                  [0, 3, 5, 4, 6, 0],\n",
    "                  [1, 0, 2, 6, 0, 3],\n",
    "                  [3, 0, 0, 0, 0, 2]])\n",
    "\n",
    "Y = torch.tensor([[5, 4, 1, 2, 3, 6],\n",
    "                  [6, 2, 3, 5, 1, 4],\n",
    "                  [4, 1, 6, 3, 2, 5],\n",
    "                  [2, 3, 5, 4, 6, 1],\n",
    "                  [1, 5, 2, 6, 4, 3],\n",
    "                  [3, 6, 4, 1, 5, 2]])\n",
    "\n",
    "X_ = torch.zeros((6,6,6))\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        if X[i][j].item() > 0:\n",
    "            X_[i][j][X[i][j].item() - 1] = 1        \n",
    "            \n",
    "Y_ = torch.zeros((6,6,6))\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        if Y[i][j].item() > 0:\n",
    "            Y_[i][j][Y[i][j].item() - 1] = 1\n",
    "            \n",
    "X = X_.unsqueeze(0)\n",
    "Y = Y_.unsqueeze(0)\n",
    "\n",
    "is_input = process_inputs(X)\n",
    "\n",
    "input = show_sudoku(X[0])\n",
    "X = X\n",
    "Y = Y[0]\n",
    "is_input = is_input[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 5, 0, 1, 0],\n",
      "        [0, 0, 3, 1, 4, 0],\n",
      "        [2, 5, 0, 0, 6, 1],\n",
      "        [0, 1, 2, 4, 3, 0],\n",
      "        [1, 0, 6, 1, 0, 4],\n",
      "        [1, 0, 0, 0, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "print(show_sudoku(X[0])) # Shape of X_in: (BxHxWxC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 4, 5, 2, 1, 6],\n",
      "        [5, 2, 3, 6, 4, 1],\n",
      "        [2, 5, 4, 1, 6, 3],\n",
      "        [6, 1, 2, 4, 3, 5],\n",
      "        [1, 3, 6, 5, 2, 4],\n",
      "        [4, 6, 1, 3, 5, 2]])\n"
     ]
    }
   ],
   "source": [
    "# Groundtruth\n",
    "print(show_sudoku(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our model and our optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = SudokuSolver(6)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our constraint function *isunique* enofrces that the number of elements of an input 6x6 tensor, which corresponds to a decoding of the network's output distribution over a row, column or square is unique. We note that our constraint function is a vanilla python function, and does not make use of any custom syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isunique(X):\n",
    "    return len(X.unique()) == 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the constraint module and declare isunique_constraint as a constraint that we can enforce at training time. We note that our constraint function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from pylon.constraint import constraint\n",
    "from pylon.sampling_solver import WeightedSamplingSolver\n",
    "\n",
    "isunique_constraint = constraint(isunique, WeightedSamplingSolver(num_samples=3000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we proceed to our normal training loop. Line 10 uses the regular corss entropy loss to learn entries that are fixed in the sudoku. We then proceed enforce the constraint on every row, column and (flattented) square in the 6x6 gridm lines 13, 14 and 18, respectively. Lines 20 through 30 then proceed to define the total loss as a convex combination of the individual constraint losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████████████████████████████████████████████████████████████████▋                             | 38/50 [02:51<01:25,  7.12s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(50)):\n",
    "    row_losses = []\n",
    "    col_losses = []\n",
    "    sqr_losses = []\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(X[:1])\n",
    "    loss = F.cross_entropy(output.view(-1,6), Y.argmax(dim=2).view(-1), reduction='none') * is_input\n",
    "    \n",
    "    for i in range(0, 6):\n",
    "        row_losses += [isunique_constraint(output[:, i])]\n",
    "        col_losses += [isunique_constraint(output[:, :, i])]\n",
    "\n",
    "    for i in range(0, 6, 2):\n",
    "        for j in range(0, 6, 3):\n",
    "            sqr_losses += [isunique_constraint(output[:, i:i+2, j:j+3].reshape(1,6,6))]\n",
    "            \n",
    "    row_losses = torch.stack(row_losses)\n",
    "    col_losses = torch.stack(col_losses)\n",
    "    sqr_losses = torch.stack(sqr_losses)\n",
    "    \n",
    "    row_multipliers = row_losses / (row_losses.sum().data + col_losses.sum().data + sqr_losses.sum().data)\n",
    "    col_multipliers = col_losses / (col_losses.sum().data + col_losses.sum().data + sqr_losses.sum().data)\n",
    "    sqr_multipliers = sqr_losses / (sqr_losses.sum().data + col_losses.sum().data + sqr_losses.sum().data)\n",
    "    \n",
    "    row_loss = (row_losses * row_multipliers).sum()\n",
    "    col_loss = (col_losses * col_multipliers).sum()\n",
    "    sqr_loss = (sqr_losses * sqr_multipliers).sum()\n",
    "    \n",
    "    total_loss = loss.sum() + row_loss + col_loss + sqr_loss\n",
    "\n",
    "    total_loss.backward()\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe, the model converges to the correct sudoku after 50 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(X[:1])\n",
    "\n",
    "print(\"Predicted Sudoku:\")\n",
    "print((output[0].argmax(dim =-1) + 1).data)\n",
    "print()\n",
    "\n",
    "print(\"Groundtruth Sudoku:\")\n",
    "print(show_sudoku(Y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is confirmed by the below heatmap showing cells where the prediction matches (blue) or doesn't (white) the groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = plt.matshow((output[0].argmax(dim =-1) == Y.argmax(dim=-1)), cmap=plt.cm.Blues, vmin=0, vmax=1)\n",
    "plt.colorbar(heatmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
